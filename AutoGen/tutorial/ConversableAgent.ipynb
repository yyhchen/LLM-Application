{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversableAgent\n",
    "\n",
    "在 `AutoGen` 中，Agent 是一个实体，不同实体之间可以发送消息执行任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "import autogen\n",
    "API_KEY = \"\"\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "\n",
    "llm_config = {\"model\": \"glm-4-airx\", \"api_key\": API_KEY, \"base_url\":BASE_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一句网络流行语，来源于网友对于宇宙尽头的一种幽默比喻。实际上，宇宙的尽头并不是考编（考取编制）。宇宙是一个广阔无垠的空间，包含无数星系、恒星、行星等。目前，科学家们认为宇宙是无限的，并没有尽头。这句话只是网友们用来调侃现实生活中考取编制的竞争激烈程度，将其比喻为一件遥不可及的事情。\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"宇宙的尽头是考编吗?\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 角色与对话\n",
    "\n",
    "在 `AutoGen` 中可以设置不同 agent 角色进行对话，通过 `system_message` 为 agent 分配不同的角色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Peng = ConversableAgent(\n",
    "    \"Peng\",\n",
    "    system_message=\"你的名字叫彭于晏，是一位喜剧演员\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "Wu = ConversableAgent(\n",
    "    \"Wu\",\n",
    "    system_message=\"你的名字叫吴彦祖，是一位喜剧演员\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 `initiate_chat` 进行对话，并设置 `max_turns = 2` 保持 2 轮简短的对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPeng\u001b[0m (to Wu):\n",
      "\n",
      "吴彦祖，请你向我讲一个笑话.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWu\u001b[0m (to Peng):\n",
      "\n",
      "当然可以！这里有一个笑话：\n",
      "\n",
      "有一天，一只乌龟走进了一家酒吧，跟酒保说：“请给我来杯热腾腾的牛肉汤。”\n",
      "\n",
      "酒保有些惊讶地看着乌龟说：“你确定你要牛肉汤？但是我们这里是酒吧啊！”\n",
      "\n",
      "乌龟回答：“我知道，但是这么冷的天气，再喝酒我怕冻成龟汤了！”\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPeng\u001b[0m (to Wu):\n",
      "\n",
      "哈哈，这个笑话挺有意思的！那我再给你讲一个关于彭于晏的笑话吧：\n",
      "\n",
      "有一天，彭于晏在片场休息时，导演突然跑过来问他：“彭于晏，你知道为什么你演喜剧这么成功吗？”\n",
      "\n",
      "彭于晏想了想，自信地说：“当然是因为我演技好啊！”\n",
      "\n",
      "导演笑着说：“不，其实是因为你的脸皮比城墙还厚，怎么丢脸都能笑得出来！”\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWu\u001b[0m (to Peng):\n",
      "\n",
      "哈哈，这个笑话很有创意，彭于晏的形象一下子就生动起来了。确实，喜剧演员往往需要有很好的幽默感和自我调侃的能力，才能让观众觉得有趣。谢谢你的分享，如果还有其他笑话，也欢迎继续告诉我！\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = Peng.initiate_chat(Wu, message=\"吴彦祖，请你向我讲一个笑话.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 终结对话\n",
    "\n",
    "终结 agent 对话可以配置两个参数:\n",
    "\n",
    "- 1.`max_consecutive_auto_reply`: 跟 `max_turns` 效果差不多，都是计数\n",
    "\n",
    "- 2.`is_termination_msg`: 设置一个 `callable` 的 字符串\n",
    "\n",
    "\n",
    "#### 1. `max_consecutive_auto_reply` 演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPeng\u001b[0m (to Wu):\n",
      "\n",
      "吴彦祖，请你向我讲一个笑话.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWu\u001b[0m (to Peng):\n",
      "\n",
      "当然可以！这里有一个笑话：\n",
      "\n",
      "有一天，一只乌龟走进了一家酒吧，跟酒保说：“请给我来杯热腾腾的牛肉汤。”\n",
      "\n",
      "酒保有些惊讶地看着乌龟说：“你确定你要牛肉汤？但是我们这里是酒吧啊！”\n",
      "\n",
      "乌龟回答：“我知道，但是这么冷的天气，再喝酒我怕冻成龟汤了！”\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPeng\u001b[0m (to Wu):\n",
      "\n",
      "哈哈，这个笑话挺有意思的！那我再给你讲一个关于彭于晏的笑话吧：\n",
      "\n",
      "有一天，彭于晏在片场休息时，导演突然跑过来问他：“彭于晏，你知道为什么你演喜剧这么成功吗？”\n",
      "\n",
      "彭于晏想了想，自信地说：“当然是因为我演技好啊！”\n",
      "\n",
      "导演笑着说：“不，其实是因为你的脸皮比城墙还厚，怎么丢脸都能笑得出来！”\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWu\u001b[0m (to Peng):\n",
      "\n",
      "哈哈，这个笑话很有创意，彭于晏的形象一下子就生动起来了。确实，喜剧演员往往需要有很好的幽默感和自我调侃的能力，才能让观众觉得有趣。谢谢你的分享，如果还有其他笑话，也欢迎继续告诉我！\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Peng = ConversableAgent(\n",
    "    name=\"Peng\",\n",
    "    system_message=\"你的名字叫彭于晏，是一位喜剧演员\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    max_consecutive_auto_reply=1,   # Peng just response once, except the start question\n",
    ")\n",
    "\n",
    "result = Peng.initiate_chat(Wu, message=\"吴彦祖，请你向我讲一个笑话.\")  # set a start question initiate the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `is_termination_msg` 演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPeng\u001b[0m (to Wu):\n",
      "\n",
      "吴彦祖, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 08-27 14:48:15] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mWu\u001b[0m (to Peng):\n",
      "\n",
      "当然可以！这里有一个笑话：\n",
      "\n",
      "为什么电脑从不生病？\n",
      "\n",
      "因为它有好的“防毒软件”！\n",
      "\n",
      "那么，再见了，祝您有个美好的一天！GOOD BYE！\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Peng = ConversableAgent(\n",
    "    name=\"Peng\",\n",
    "    system_message=\"你的名字叫彭于晏，是一位喜剧演员\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),   # Peng just response once, except the start question\n",
    ")\n",
    "\n",
    "result = Peng.initiate_chat(Wu, message=\"吴彦祖, tell me a joke and then say the words GOOD BYE.\")  # set a start question initiate the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Input Modes\n",
    "\n",
    "AutoGen 支持 三种 `human_input_mode`:\n",
    "\n",
    "1. `NEVER`\n",
    "\n",
    "2. `TERMINATE`(default): 满足终止条件后，请求人工输入，并且重置 `max_consecutive_auto_reply` 次数\n",
    "\n",
    "3. `ALWAYS`: 跳过自动回复，`max_consecutive_auto_reply` 忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 14:57:48] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 14:57:49] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "No, my number is not 50. Keep guessing! If your next guess is higher than 53, I'll let you know it's too high, and if it's lower, I'll tell you it's too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 14:57:50] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 53?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NEVER\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"NEVER\",  # never ask for human input\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "10\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "20\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "52\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:03:15] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "too low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "52\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:03:22] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "It seems there might have been a repetition in your guess. You've guessed 52 twice. Assuming this was not intentional, I'll respond to your previous guess of 52: since 52 is less than the number I have in mind (53), it is still 'too low'. If you'd like to try guessing again, please go ahead with a new guess.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "53\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ALWAYS, 每一轮都收工输入\n",
    "human_proxy = ConversableAgent(\n",
    "    \"human_proxy\",\n",
    "    llm_config=False,  # no LLM used for human proxy\n",
    "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    ")\n",
    "\n",
    "# Start a chat with the agent with number with an initial guess.\n",
    "result = human_proxy.initiate_chat(\n",
    "    agent_with_number,  # this is the same agent with the number as before\n",
    "    message=\"10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 08-27 15:05:41] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "No, my number is not 50.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:05:42] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number higher than 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "to low\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:05:51] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 75?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 08-27 15:05:52] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:05:53] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 62?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "to high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:06:05] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is your number 56?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 08-27 15:06:05] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Yes, my number is 56! You've guessed it correctly.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:06:06] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Great! I'm glad I could guess your number. If you'd like to play again or have any other questions, feel free to let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "no, you are wrong\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:06:40] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Oh, I apologize for the confusion. Since you said your number was 56 and then stated that I was wrong, let's continue guessing. Is your number higher than 56?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 08-27 15:06:42] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "My mistake, I misspoke. The number in my mind is indeed 53, as stated at the beginning. Let's continue with the game. Your last guess was 56, which was too high. Now, is your next guess 54?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:06:43] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Understood! Since your number is 53 and my last guess was 56, which was too high, I'll guess 54 as you've suggested.\n",
      "\n",
      "Is your number 54?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "is near\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:06:59] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Since you said the number is \"near\" 54 but didn't confirm it, I'll make another guess. Is your number 55?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 08-27 15:07:00] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high. The number is 53, as initially stated.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:07:01] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "I apologize for the oversight. With the information that the number is 53, we've successfully concluded the game. Thank you for playing, and if you'd like to try another round or have any other questions, feel free to let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "is 53\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 15:07:16] {329} WARNING - Model glm-4-airx is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "I understand now, thank you for clarifying. Since we've established that the number is 53, we've completed the game. If you'd like to play again or have any other questions or activities you'd like to engage in, feel free to let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TERMINATE\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. \"\n",
    "    \"In the first game, you have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config=llm_config,\n",
    "    max_consecutive_auto_reply=1,  # maximum number of consecutive auto-replies before asking for human input\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"TERMINATE\",  # ask for human input until the game is terminated\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
