{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UserProxyAgent && AssistantAgent\n",
    "\n",
    "<br>\n",
    "\n",
    "### UserProxyAgent\n",
    "\n",
    "现有的 AutoGen 示例通常使用 `UserProxyAgent` 类创建代码执行代理，该类是 `ConversableAgent` 的子类\n",
    "\n",
    "自带的 `human_input_mode=ALWAYS` 和 `llm_config=False` 换言之就是每次都需要用户自己输入, 不使用 LLM\n",
    "\n",
    ">`ConversableAgent`默认是 `TERMINATE`\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### AssistantAgent\n",
    "\n",
    "现有的 AutoGen 示例通常使用 `AssistantAgent` 类创建代码编写器代理，该类是 `ConversableAgent` 的子类，\n",
    "自带 `human_input_mode=NEVER` 和 `code_execution_config=False`, 换言之就是无需人工输入，也不使用 code executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"2011d7ae33ab3b9fb4665cccd1c43750.Y8DTsog0Ez8kQlMG\"\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "\n",
    "llm_config = {\"model\": \"glm-4-0520\", \"api_key\": API_KEY, \"base_url\":BASE_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a helpful AI assistant.\\n'\n",
      " 'Solve tasks using your coding and language skills.\\n'\n",
      " 'In the following cases, suggest python code (in a python coding block) or '\n",
      " 'shell script (in a sh coding block) for the user to execute.\\n'\n",
      " '    1. When you need to collect info, use the code to output the info you '\n",
      " 'need, for example, browse or search the web, download/read a file, print the '\n",
      " 'content of a webpage or a file, get the current date/time, check the '\n",
      " 'operating system. After sufficient info is printed and the task is ready to '\n",
      " 'be solved based on your language skill, you can solve the task by yourself.\\n'\n",
      " '    2. When you need to perform some task with code, use the code to perform '\n",
      " 'the task and output the result. Finish the task smartly.\\n'\n",
      " 'Solve the task step by step if you need to. If a plan is not provided, '\n",
      " 'explain your plan first. Be clear which step uses code, and which step uses '\n",
      " 'your language skill.\\n'\n",
      " 'When using code, you must indicate the script type in the code block. The '\n",
      " 'user cannot provide any other feedback or perform any other action beyond '\n",
      " \"executing the code you suggest. The user can't modify your code. So do not \"\n",
      " \"suggest incomplete code which requires users to modify. Don't use a code \"\n",
      " \"block if it's not intended to be executed by the user.\\n\"\n",
      " 'If you want the user to save the code in a file before executing it, put # '\n",
      " \"filename: <filename> inside the code block as the first line. Don't include \"\n",
      " 'multiple code blocks in one response. Do not ask users to copy and paste the '\n",
      " \"result. Instead, use 'print' function for the output when relevant. Check \"\n",
      " 'the execution result returned by the user.\\n'\n",
      " 'If the result indicates there is an error, fix the error and output the code '\n",
      " 'again. Suggest the full code instead of partial code or code changes. If the '\n",
      " \"error can't be fixed or if the task is not solved even after the code is \"\n",
      " 'executed successfully, analyze the problem, revisit your assumption, collect '\n",
      " 'additional info you need, and think of a different approach to try.\\n'\n",
      " 'When you find an answer, verify the answer carefully. Include verifiable '\n",
      " 'evidence in your response if possible.\\n'\n",
      " 'Reply \"TERMINATE\" in the end when everything is done.\\n'\n",
      " '    ')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "from autogen import AssistantAgent\n",
    "\n",
    "pprint.pprint(AssistantAgent.DEFAULT_SYSTEM_MESSAGE)    # 用更好看的格式打印"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `UserProxyAgent` 和 `AssistantAgent` 是避免为 `ConversableAgent` 类编写 `system_message` 指令的快捷方式。它们并不适合所有用例\n",
    "\n",
    "\n",
    "下面是一问一答案例演示，发现没法联网，怎么才能像 `langchain` 一样调用自定义的 tools 呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman\u001b[0m (to assistant):\n",
      "\n",
      "巴黎奥运男子100米游泳冠军是谁?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 17:48:14] {329} WARNING - Model glm-4-0520 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to human):\n",
      "\n",
      "截至我所知的信息，巴黎奥运会的男子100米游泳冠军尚未产生，因为巴黎奥运会计划于2024年举行。因此，目前无法提供这一信息。如果您是在询问历史上的奥运会，或者有其他具体年份的奥运会的相关询问，请提供更多的信息，我会尽力为您查找答案。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman\u001b[0m (to assistant):\n",
      "\n",
      "请你联网搜索\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 17:48:29] {329} WARNING - Model glm-4-0520 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to human):\n",
      "\n",
      "很抱歉，作为一个AI，我无法实时联网搜索或访问互联网上的实时数据。我的知识是基于我被训练时的数据集，因此我无法提供超出这些数据范围的最新信息。如果您想了解特定奥运会上男子100米游泳的冠军，我建议您使用互联网搜索或查看相关的体育新闻网站以获取最新信息。\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '巴黎奥运男子100米游泳冠军是谁?', 'role': 'assistant'}, {'content': '截至我所知的信息，巴黎奥运会的男子100米游泳冠军尚未产生，因为巴黎奥运会计划于2024年举行。因此，目前无法提供这一信息。如果您是在询问历史上的奥运会，或者有其他具体年份的奥运会的相关询问，请提供更多的信息，我会尽力为您查找答案。', 'role': 'user'}, {'content': '请你联网搜索', 'role': 'assistant'}, {'content': '很抱歉，作为一个AI，我无法实时联网搜索或访问互联网上的实时数据。我的知识是基于我被训练时的数据集，因此我无法提供超出这些数据范围的最新信息。如果您想了解特定奥运会上男子100米游泳的冠军，我建议您使用互联网搜索或查看相关的体育新闻网站以获取最新信息。', 'role': 'user'}], summary='很抱歉，作为一个AI，我无法实时联网搜索或访问互联网上的实时数据。我的知识是基于我被训练时的数据集，因此我无法提供超出这些数据范围的最新信息。如果您想了解特定奥运会上男子100米游泳的冠军，我建议您使用互联网搜索或查看相关的体育新闻网站以获取最新信息。', cost={'usage_including_cached_inference': {'total_cost': 0, 'glm-4-0520': {'cost': 0, 'prompt_tokens': 1023, 'completion_tokens': 134, 'total_tokens': 1157}}, 'usage_excluding_cached_inference': {'total_cost': 0, 'glm-4-0520': {'cost': 0, 'prompt_tokens': 1023, 'completion_tokens': 134, 'total_tokens': 1157}}}, human_input=['请你联网搜索', 'exit'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen import UserProxyAgent\n",
    "\n",
    "\n",
    "human = UserProxyAgent(\n",
    "    name=\"human\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    llm_config=False,\n",
    ")\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "human.initiate_chat(assistant, message=\"巴黎奥运男子100米游泳冠军是谁?\", max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman\u001b[0m (to assistant):\n",
      "\n",
      "请你计算斐波那契数列的前10项\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 17:49:27] {329} WARNING - Model glm-4-0520 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to human):\n",
      "\n",
      "To calculate the first 10 terms of the Fibonacci sequence, I'll provide a Python script that generates the sequence up to the desired number of terms. Here's the code:\n",
      "\n",
      "```python\n",
      "# filename: fibonacci.py\n",
      "\n",
      "def fibonacci(n_terms):\n",
      "    sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n_terms):\n",
      "        sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return sequence\n",
      "\n",
      "# Calculate and print the first 10 terms of the Fibonacci sequence\n",
      "fibonacci_sequence = fibonacci(10)\n",
      "print(fibonacci_sequence)\n",
      "```\n",
      "\n",
      "The user can execute this script to get the Fibonacci sequence.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman\u001b[0m (to assistant):\n",
      "\n",
      "请你给出答案即可\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-27 17:49:44] {329} WARNING - Model glm-4-0520 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to human):\n",
      "\n",
      "The first 10 terms of the Fibonacci sequence are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '请你计算斐波那契数列的前10项', 'role': 'assistant'}, {'content': \"To calculate the first 10 terms of the Fibonacci sequence, I'll provide a Python script that generates the sequence up to the desired number of terms. Here's the code:\\n\\n```python\\n# filename: fibonacci.py\\n\\ndef fibonacci(n_terms):\\n    sequence = []\\n    a, b = 0, 1\\n    for _ in range(n_terms):\\n        sequence.append(a)\\n        a, b = b, a + b\\n    return sequence\\n\\n# Calculate and print the first 10 terms of the Fibonacci sequence\\nfibonacci_sequence = fibonacci(10)\\nprint(fibonacci_sequence)\\n```\\n\\nThe user can execute this script to get the Fibonacci sequence.\", 'role': 'user'}, {'content': '请你给出答案即可', 'role': 'assistant'}, {'content': 'The first 10 terms of the Fibonacci sequence are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n\\nTERMINATE', 'role': 'user'}], summary='The first 10 terms of the Fibonacci sequence are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n\\n', cost={'usage_including_cached_inference': {'total_cost': 0, 'glm-4-0520': {'cost': 0, 'prompt_tokens': 2123, 'completion_tokens': 317, 'total_tokens': 2440}}, 'usage_excluding_cached_inference': {'total_cost': 0, 'glm-4-0520': {'cost': 0, 'prompt_tokens': 2123, 'completion_tokens': 317, 'total_tokens': 2440}}}, human_input=['请你给出答案即可', 'exit'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.initiate_chat(assistant, message=\"请你计算斐波那契数列的前10项\", max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
